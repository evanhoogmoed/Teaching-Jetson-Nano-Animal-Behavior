import torch
import torchvision
import torch.nn.functional as F

model = torchvision.models.alexnet(pretrained=False)
model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 4)

collision_model = torchvision.models.alexnet(pretrained=False)
collision_model.classifier[6] = torch.nn.Linear(collision_model.classifier[6].in_features, 3)
collision_model.load_state_dict(torch.load('../collision_avoidance/best_model.pth'))
device = torch.device('cuda')
collision_model = collision_model.to(device)

model.load_state_dict(torch.load('best_model_pred_prey.pth'))
#device = torch.device('cuda')
model = model.to(device)

import cv2
import numpy as np

mean = 255.0 * np.array([0.485, 0.456, 0.406])
stdev = 255.0 * np.array([0.229, 0.224, 0.225])

normalize = torchvision.transforms.Normalize(mean, stdev)

def preprocess(camera_value):
    global device, normalize
    x = camera_value
    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)
    x = x.transpose((2, 0, 1))
    x = torch.from_numpy(x).float()
    x = normalize(x)
    x = x.to(device)
    x = x[None, ...]
    return x
    
import traitlets
from IPython.display import display
import ipywidgets.widgets as widgets
from jetbot import Camera, bgr8_to_jpeg

camera = Camera.instance(width=224, height=224)
image = widgets.Image(format='jpeg', width=224, height=224)
predator_slider = widgets.FloatSlider(description = 'predator',min = 0.0, max=1.0, orientation = 'vertical')
predator_slider = widgets.FloatSlider(description = 'predator',min = 0.0, max=1.0, orientation = 'vertical')
prey_slider = widgets.FloatSlider(description='prey', min=0.0, max=1.0, orientation='vertical',
                                        readout=True, readout_format='.4f')
none_slider = widgets.FloatSlider(description='none', min=0.0, max=1.0, orientation='vertical',
                                        readout=True, readout_format='.4f')
camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)
both_slider = widgets.FloatSlider(description='both', min=0.0, max=1.0, orientation='vertical',
                                        readout=True, readout_format='.4f')
                                        
display(widgets.HBox([image, predator_slider, prey_slider, none_slider, both_slider]))

from jetbot import Robot

robot = Robot()

import torch.nn.functional as F
import time

def update(change):
    global predator_slider, prey_slider, none_slider, both_slider, robot
    x = change['new'] 
    x = preprocess(x)
    y = model(x)
    
    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)
    y = F.softmax(y, dim=1)
    
    prob_predator = float(y.flatten()[0])
    prob_prey = float(y.flatten()[1])
    prob_none = float(y.flatten()[2])
    prob_both = float(y.flatten()[3])
    
    predator_slider.value = prob_predator
    prey_slider.value = prob_prey
    none_slider.value = prob_none
    both_slider.value = prob_both
    

    if prob_predator > 0.5:
        robot.forward(-.5)
        #robot.left(1.0)
        
    elif prob_prey > 0.5:
        robot.forward(0.5)
    
    elif prob_none > 0.5:
        robot.forward(0.2)
    
    elif prob_none > 0.5:
        time.sleep(1.0)
    
    time.sleep(0.001)
        
update({'new': camera.value})  # we call the function once to intialize
camera.observe(update, names='value')

#execute in different block
#stops robot
import time

camera.unobserve(update, names='value')

time.sleep(0.1)  # add a small sleep to make sure frames have finished processing

robot.stop()
